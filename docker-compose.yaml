version: '3.8'

services:
  human-keypoint-ai-service:
    image: human-keypoint-ai-service
    build:
      context: .
      dockerfile: docker/fastapi-ai.Dockerfile
    ports:
      - "8005:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - KEYPOINT_WEIGHT_PATH=/app/models/model.onnx
      - KEYPOINT_DEVICE=gpu
      - KEYPOINT_MAX_IMAGE_SIZE=1024

  triton-mount:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    volumes:
      - ./models:/models
    command: tritonserver --model-repository=/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  triton-build:
    build:
      context: .
      dockerfile: docker/triton.Dockerfile
    ports:
      - "8000:8000"
      - "8001:8001"
      - "8002:8002"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  streamlit-app:
    build:
      context: .
      dockerfile: docker/app.Dockerfile
    ports:
      - "8501:8501"

  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./docker/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml